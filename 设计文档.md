# 基于 DuckDB 的通用 MCP 知识库详细设计文档

## 1. 系统概述

本系统是一个基于 DuckDB 构建的专用知识引擎，采用 MCP (Model Context Protocol) 架构。其核心目标是为全自动智能体（Agent）提供一个具备**精准检索、Git 可审计、且支持复杂批量操作**的持久化记忆层。

### 核心哲学

* **一库一服 (Dedicated Mode)**：每个实例独占一个目录，通过环境变量 `KB_PATH` 锁定。
* **文件驱动 (File-Driven)**：所有知识变更必须通过修改 `.jsonl` 事实文件完成。
* **成本优先 (Cost Efficiency)**：内置向量缓存，避免对相同文本重复调用大模型 API。

## 2. 物理架构与目录规范

### 2.1 目录树结构

```
/knowledge-bases/{kb_id}/
├── README.md             # 知识库背景与规则说明
├── schema.sql            # 数据库 DDL 定义 (Source of Truth)
├── user_dict.txt         # 中文分词自定义词典
├── data/                 # 核心事实数据 (Git 存储)
│   ├── characters.jsonl
│   └── locations.jsonl
└── .build/               # 运行时产物 (Git 忽略)
    ├── knowledge.db      # DuckDB 二进制文件
    └── temp_import.jsonl # 阶段式导入缓冲区


```

## 3. 数据库设计

系统除业务表外，维护三张核心系统表。

### 3.1 全局搜索索引表 (`_sys_search`)

用于混合检索，增加元数据字段。

```
CREATE TABLE _sys_search (
    ref_id VARCHAR,             -- 关联业务表的主键 ID
    source_table VARCHAR,       -- 来源表名
    source_field VARCHAR,       -- 来源字段名
    segmented_text TEXT,        -- Python 层分词结果
    embedding_id VARCHAR,       -- 指向缓存表的 Hash Key
    metadata JSON,              -- 自动提取的行元数据 (如原始字段快照)
    priority_weight FLOAT DEFAULT 1.0,
    PRIMARY KEY (ref_id, source_table, source_field)
);


```

### 3.2 向量缓存表 (`_sys_cache`)

**优化点**：通过内容的 MD5 或 SHA256 哈希值缓存向量，大幅降低 API 调用成本。

```
CREATE TABLE _sys_cache (
    content_hash VARCHAR PRIMARY KEY, -- 原始文本的哈希值
    embedding FLOAT[1536],            -- 向量数据
    last_used TIMESTAMP               -- 用于清理旧缓存
);


```

## 4. 核心逻辑优化

### 4.1 向量生成工作流 (带缓存)

1. **输入**：一段文本内容 \$T\$。
2. **计算哈希**：\$H = Hash(T)\$。
3. **查询缓存**：`SELECT embedding FROM _sys_cache WHERE content_hash = H`。
4. **命中**：直接返回。
5. **未命中**：调用 Embedding API -> 存入 `_sys_cache` -> 返回。

### 4.2 混合搜索逻辑

* **计算公式**：\$Final\\\_Score = (BM25 \times 0.4 + Vector \times 0.6) \times priority\\\_weight\$。
* **元数据提取**：在 `sync` 过程中，除了被索引的文本外，该行的其他 Key-Value 对会自动序列化为 JSON 存入 `metadata` 字段。

## 5. MCP 工具箱接口定义

### 5.1 环境管理类

* **`sync_knowledge_base()`**
  * **功能**：同步 `data/*.jsonl` 到数据库。
  * **增量检查**：通过文件的最后修改时间判断是否需要重建某张表的索引。
* **`get_schema_info()`**
  * **功能**：返回 `schema.sql` (带注释解析) 和 Mermaid 格式的 ER 图。

### 5.2 知识检索类

* **`smart_search(query, limit=10, table_filter=null)`**
  * **功能**：执行混合搜索，结果包含 `metadata` 方便 Agent 直接读取背景。
* **`query_raw_sql(sql)`**
  * **安全逻辑封装**：
    1. **预检测**：自动检查是否包含 `LIMIT`。若无且为 `SELECT` 语句，强制追加 `LIMIT 1000`。
    2. **只读检查**：利用 DuckDB 连接参数禁止写操作。
    3. **异常捕获**：返回带详细 SQL 错误信息的结构化 JSON。

### 5.3 事实维护类 (带错误反馈)

* **`validate_and_import(table_name, temp_file_path)`**
  * **功能**：验证预导入数据并合并到生产环境。
  * **错误反馈循环 (Feedback Loop)**：
    * 校验失败时，不只返回 "Error"，而是返回：`"第 12 行格式错误：字段 'level' 期待数字，实际得到 'high'。请更正后重试。"`。
    * 校验通过后，自动将数据从 `.build/` 移入 `data/` 并触发 `sync`。

## 6. 运行安全与性能

1. **自动垃圾回收**：定期清理 `_sys_cache` 中超过 30 天未被引用的向量。
2. **查询限流**：针对 StdIO 传输，单次查询结果集大小严格控制在 2MB 以内。
3. **原子写入**：文件操作采用“先写副本再重命名”的策略，防止意外中断导致 `.jsonl` 损坏。

## 7. 改进后对比

| **功能点**    | **原方案**     | **优化方案**               | **收益**           |
| ---------- | ----------- | ---------------------- | ---------------- |
| **向量成本**   | 每次同步重复调用    | **基于 Hash 的持久化缓存**     | 成本降低 80% 以上      |
| **查询安全**   | 依赖 Agent 自律 | **SQL 引擎级自动 Limit 保护** | 防止内存溢出和管道堵塞      |
| **数据录入**   | 覆盖式导入       | **行级校验与具体错误定位**        | 显著提升 Agent 自修复能力 |
| **上下文丰富度** | 仅返回匹配片段     | **自动元数据提取 (Metadata)** | 检索结果无需二次二次关联     |
