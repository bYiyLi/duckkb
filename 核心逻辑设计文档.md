DuckKB 核心引擎详细设计文档 (终极版)1. 系统愿景与架构哲学DuckKB 是一个专为 AI Agent 环境设计的“二位一体”知识引擎（向量、全文）。计算与存储解耦：DuckDB 仅作为高性能运行时计算层（Runtime），不产生持久化 .db 文件。真理源于文件：所有知识以 Git 托管的 JSONL 文本形式存在，确保每一条知识的变更都“人类可读、审计透明”。确定性还原：通过物理 ID (__id) 的持久化，确保系统在每次启动后，派生的搜索索引能精准回溯到原始数据。2. Ontology 本体配置规范系统通过 config.yaml 驱动，自动完成 DDL 生成、切片逻辑分配与检索路由。2.1 全局配置 (Global)chunk_size: 文本切片长度（默认 800 字符），解决长文本向量化后的特征稀释。embedding_model: 指定使用的向量模型协议。tokenizer: 指定中文分词驱动（如 jieba）。2.2 建模规范节点 (Nodes): 独立实体，拥有业务主键 (identity)。关系 (Edges): 采用“点线分离”模式，所有关系均通过独立的边表存储（RPG 模型），支持 1:1, N:1, N:N 场景。global:
  chunk_size: 800
  embedding_model: "text-embedding-3-small"

nodes:
  Document:
    table: "docs"
    identity: "doc_uri"
    schema:
      type: object
      required: ["doc_uri", "content"]
      properties:
        doc_uri: { type: string }
        content: { type: string, description: "长文本内容" }
    search:
      full_text: ["content"]
      vectors: ["content"]

edges:
  REFERENCES:
    label: "references"
    from: "Document"
    to: "Document"
    schema:
      type: object
      properties:
        ref_type: { type: string }
3. 运行时数据布局 (Schema)运行时 DuckDB 内部维护三类表，通过 __id 实现逻辑闭环。3.1 业务主表 (Node/Edge Tables)存储完整的业务字段和审计字段。__id: BIGINT (唯一主键，必须导出的真理)。__created_at / __updated_at: TIMESTAMP。[Business Fields]: 用户定义的业务属性。3.2 搜索索引表 (search_index)运行时唯一检索入口。将长文本拆分为分片以提高精度。source_table: 来源表名。source_id: 对应主表的 __id。chunk_seq: 片段序号。content: 原始片段（用于 Agent 阅读展示）。fts_content: 预分词片段（中文加空格，仅供 DuckDB FTS 使用）。vector: 向量数据（FLOAT[]）。3.3 搜索持久化缓存 (search_cache)该表用于跨启动周期加速。content_hash: content 的唯一哈希。fts_content / vector: 预计算的分词结果与向量。持久化: 导出为 search_cache.parquet，由 Git LFS 托管。4. 核心工作流4.1 原子同步协议 (Shadow Copy)当发生数据变更时，执行以下“全或无”的操作：DB 事务写入: 在事务中更新业务表和 search_index。分词与切片: 对变更内容执行 Chunking -> 分词处理 -> 向量查询（优先读缓存，缺失则调 API）。影子导出:业务数据: 强制按 identity 排序，COPY ... TO ... (FORMAT JSONL)。缓存数据: COPY ... TO ... (FORMAT PARQUET)。原子替换: 在操作系统层面通过 rename 瞬间替换旧的 data/ 目录。提交: 完成 COMMIT。4.2 启动构建协议 (Bootstrapping)由于没有物理 DB 文件，系统启动时执行：全量重载: 扫描 JSONL 目录，将所有数据载入 DuckDB 内存，并保留原始 __id。缓存唤醒: 从 LFS 托管的 Parquet 加载 search_cache。索引镜像还原:扫描业务表需要索引的字段，进行 Chunking。通过 content_hash 从缓存中一键回填 fts_content 和 vector。由于 __id 未变，search_index 的 source_id 依然能精准指向内存中的业务记录。5. 混合检索与召回策略 (Hybrid RRF)系统对查询请求执行两路并发处理：文本检索 (FTS): 在 search_index.fts_content 执行关键词匹配，返回 Top-K。语义检索 (Vector): 执行余弦相似度计算，返回 Top-K。排序融合 (RRF):使用 $Score = \sum \frac{1}{k + Rank}$ 算法合并两路排名。根据高分片段的 source_id 回捞业务主表。6. Git 持久化规范6.1 目录结构/data
  /nodes
    /{table_name}/{YYYYMMDD}/part_{NNN}.jsonl
  /edges
    /{label_name}/{YYYYMMDD}/part_{NNN}.jsonl
  /indices
    /search_cache.parquet  <-- Git LFS 托管
6.2 分片策略时间分区: 按天创建文件夹，解决 Git 在单一目录下管理上万文件导致的卡顿。确定性排序: 导出时 ORDER BY identity。这对于 Git 极为关键，它确保了数据更新时只有变动的行会产生 Diff，而不是整个文件重排。7. 技术实现细节 (DuckDB 实现)分词处理: 封装 UDF (User Defined Function) 或在应用层处理后再写入 fts_content。向量计算: SELECT array_cosine_similarity(vector, [0.1, ...]) AS dist FROM search_index ORDER BY dist DESC LIMIT 10。复合主键 Join: 运行时利用 identity 列拼接生成的唯一哈希进行高效 JOIN。