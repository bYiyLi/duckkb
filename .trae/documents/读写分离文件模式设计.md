# 方案 C: 读写分离 + 文件模式详细设计

## 一、设计目标

将 DuckKB 从**内存模式**改为**文件模式**，实现：
- ✅ 多个查询并发执行（只读连接池）
- ✅ 导入与查询并发执行（读写分离）
- ❌ 多个导入并发执行（DuckDB 单一写入者限制）

## 二、前置验证：DuckDB 并发读写能力测试

在实施前，需要验证 DuckDB 文件模式是否支持：
1. 多个只读连接并发读取
2. 写连接与只读连接并发（读写不阻塞）
3. 只读连接能否读取到写入中的数据（MVCC）

### 2.1 测试用例设计

```python
# tests/test_duckdb_concurrency.py
"""DuckDB 并发读写能力验证测试。"""

import asyncio
import tempfile
from pathlib import Path

import duckdb
import pytest


class TestDuckDBConcurrency:
    """验证 DuckDB 文件模式的并发能力。"""

    @pytest.fixture
    def db_path(self, tmp_path: Path) -> Path:
        """创建临时数据库路径。"""
        return tmp_path / "test.db"

    def test_single_write_connection(self, db_path: Path) -> None:
        """测试单一写连接的基本功能。"""
        conn = duckdb.connect(str(db_path))
        conn.execute("CREATE TABLE test (id INTEGER, name VARCHAR)")
        conn.execute("INSERT INTO test VALUES (1, 'Alice')")
        result = conn.execute("SELECT * FROM test").fetchall()
        assert result == [(1, "Alice")]
        conn.close()

    def test_readonly_connection(self, db_path: Path) -> None:
        """测试只读连接。"""
        # 先用写连接创建数据
        writer = duckdb.connect(str(db_path))
        writer.execute("CREATE TABLE test (id INTEGER, name VARCHAR)")
        writer.execute("INSERT INTO test VALUES (1, 'Alice')")
        writer.close()

        # 用只读连接读取
        reader = duckdb.connect(str(db_path), read_only=True)
        result = reader.execute("SELECT * FROM test").fetchall()
        assert result == [(1, "Alice")]

        # 只读连接不能写入
        with pytest.raises(duckdb.Error):
            reader.execute("INSERT INTO test VALUES (2, 'Bob')")

        reader.close()

    def test_multiple_readonly_connections(self, db_path: Path) -> None:
        """测试多个只读连接并发读取。"""
        # 先用写连接创建数据
        writer = duckdb.connect(str(db_path))
        writer.execute("CREATE TABLE test (id INTEGER, name VARCHAR)")
        writer.execute("INSERT INTO test VALUES (1, 'Alice')")
        writer.close()

        # 创建多个只读连接
        readers = [duckdb.connect(str(db_path), read_only=True) for _ in range(5)]

        # 所有只读连接都能读取
        for reader in readers:
            result = reader.execute("SELECT * FROM test").fetchall()
            assert result == [(1, "Alice")]

        for reader in readers:
            reader.close()

    def test_read_write_concurrent(self, db_path: Path) -> None:
        """测试读写并发（核心测试）。"""
        writer = duckdb.connect(str(db_path))
        writer.execute("CREATE TABLE test (id INTEGER, name VARCHAR)")
        writer.execute("INSERT INTO test VALUES (1, 'Alice')")

        # 创建只读连接
        reader = duckdb.connect(str(db_path), read_only=True)

        # 写连接开始事务
        writer.begin()
        writer.execute("INSERT INTO test VALUES (2, 'Bob')")

        # 只读连接应该看不到未提交的数据（MVCC）
        result = reader.execute("SELECT * FROM test").fetchall()
        assert result == [(1, "Alice")], "只读连接不应看到未提交的数据"

        # 写连接提交
        writer.commit()

        # 只读连接现在可以看到提交的数据
        result = reader.execute("SELECT * FROM test").fetchall()
        assert result == [(1, "Alice"), (2, "Bob")], "只读连接应看到已提交的数据"

        reader.close()
        writer.close()

    def test_write_connection_exclusion(self, db_path: Path) -> None:
        """测试写连接的排他性。"""
        writer1 = duckdb.connect(str(db_path))
        writer1.execute("CREATE TABLE test (id INTEGER, name VARCHAR)")

        # 第二个写连接应该被阻塞或失败
        # DuckDB 在文件模式下，多个写连接会互相阻塞
        writer2 = duckdb.connect(str(db_path))

        # 这里的行为取决于 DuckDB 的锁实现
        # 通常会阻塞或抛出异常
        writer1.close()
        writer2.close()

    @pytest.mark.asyncio
    async def test_async_read_write_concurrent(self, db_path: Path) -> None:
        """测试异步环境下的读写并发。"""
        writer = duckdb.connect(str(db_path))
        writer.execute("CREATE TABLE test (id INTEGER, name VARCHAR)")

        async def write_data():
            def _write():
                writer.begin()
                for i in range(10):
                    writer.execute(f"INSERT INTO test VALUES ({i}, 'User{i}')")
                writer.commit()

            await asyncio.to_thread(_write)

        async def read_data():
            def _read():
                reader = duckdb.connect(str(db_path), read_only=True)
                result = reader.execute("SELECT COUNT(*) FROM test").fetchone()
                reader.close()
                return result[0] if result else 0

            return await asyncio.to_thread(_read)

        # 并发执行读写
        write_task = asyncio.create_task(write_data())
        read_tasks = [asyncio.create_task(read_data()) for _ in range(5)]

        await write_task
        read_results = await asyncio.gather(*read_tasks)

        # 所有读取都应该成功
        assert all(r >= 0 for r in read_results)

        writer.close()

    def test_wal_mode(self, db_path: Path) -> None:
        """测试 WAL 模式对并发的影响。"""
        writer = duckdb.connect(str(db_path))
        writer.execute("PRAGMA wal_mode='true'")
        writer.execute("CREATE TABLE test (id INTEGER, name VARCHAR)")
        writer.execute("INSERT INTO test VALUES (1, 'Alice')")

        # WAL 模式下，读操作应该不会被写操作阻塞
        reader = duckdb.connect(str(db_path), read_only=True)
        result = reader.execute("SELECT * FROM test").fetchall()
        assert result == [(1, "Alice")]

        reader.close()
        writer.close()
```

### 2.2 验证步骤

```bash
# 运行测试
uv run pytest tests/test_duckdb_concurrency.py -v

# 如果测试通过，说明 DuckDB 支持：
# 1. 多个只读连接并发读取 ✅
# 2. 读写并发（MVCC） ✅
# 3. WAL 模式提升并发性能 ✅
```

## 三、架构设计

### 3.1 整体架构

```
┌─────────────────────────────────────────────────────────────────┐
│                        Engine 实例                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────────────┐      ┌─────────────────────────────┐  │
│  │    写连接管理器      │      │       读连接管理器          │  │
│  │  (WriterManager)    │      │     (ReaderManager)         │  │
│  │                     │      │                             │  │
│  │  ┌───────────────┐  │      │  ┌─────┐ ┌─────┐ ┌─────┐  │  │
│  │  │ writer_conn   │  │      │  │ r1  │ │ r2  │ │ r3  │  │  │
│  │  │ (独占模式)     │  │      │  │     │ │     │ │     │  │  │
│  │  └───────────────┘  │      │  └─────┘ └─────┘ └─────┘  │  │
│  │         │           │      │         │                  │  │
│  │  ┌───────────────┐  │      │  ┌─────────────────────┐  │  │
│  │  │ write_lock    │  │      │  │ 连接池 (可选)        │  │  │
│  │  │ (asyncio.Lock)│  │      │  │                     │  │  │
│  │  └───────────────┘  │      │  └─────────────────────┘  │  │
│  └─────────────────────┘      └─────────────────────────────┘  │
│           │                              │                      │
│           └──────────┬───────────────────┘                      │
│                      ▼                                          │
│              ┌──────────────┐                                   │
│              │   kb.db      │                                   │
│              │  (文件模式)   │                                   │
│              └──────────────┘                                   │
│                      │                                          │
│              ┌──────────────┐                                   │
│              │  WAL 日志     │                                   │
│              │  (可选)       │                                   │
│              └──────────────┘                                   │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 核心组件

#### 3.2.1 数据库配置模型

```python
# src/duckkb/core/config/models.py

class DatabaseConfig(BaseModel):
    """数据库配置模型。

    Attributes:
        mode: 数据库模式，"memory" 或 "file"。
        filename: 数据库文件名，默认 "kb.db"。
        wal_mode: 是否启用 WAL 模式，默认 True。
        threads: 并行查询线程数，默认 4。
    """

    mode: Literal["memory", "file"] = "file"
    filename: str = "kb.db"
    wal_mode: bool = True
    threads: int = Field(default=4, ge=1, le=16)


class CoreConfig(BaseModel):
    """核心引擎配置模型。"""

    storage: StorageConfig
    global_config: GlobalConfig = Field(default_factory=GlobalConfig)
    embedding_dim: int = Field(default=1536, ge=1, le=4096)
    database: DatabaseConfig = Field(default_factory=DatabaseConfig)  # 新增
```

#### 3.2.2 数据库连接管理器

```python
# src/duckkb/core/mixins/db.py
"""数据库连接管理 Mixin（读写分离版）。"""

import duckdb
from contextlib import contextmanager
from pathlib import Path
from threading import Lock
from typing import Generator

from duckkb.core.base import BaseEngine
from duckkb.logger import logger


class DBMixin(BaseEngine):
    """数据库连接管理 Mixin（读写分离版）。

    支持两种模式：
    - memory: 内存模式（向后兼容），单一连接
    - file: 文件模式，读写分离

    文件模式下：
    - 写操作使用单一独占连接
    - 读操作使用只读连接（每次创建新连接或从池中获取）
    - MVCC 保证读写不阻塞
    """

    def __init__(self, *args, **kwargs) -> None:
        """初始化数据库 Mixin。"""
        super().__init__(*args, **kwargs)
        self._writer_conn: duckdb.DuckDBPyConnection | None = None
        self._write_lock = Lock()  # 线程锁，保护写连接
        self._db_path: Path | None = None

    @property
    def conn(self) -> duckdb.DuckDBPyConnection:
        """获取写连接（向后兼容）。

        注意：此属性返回写连接，仅用于写操作。
        读操作请使用 reader() 上下文管理器。
        """
        return self.writer_conn

    @property
    def writer_conn(self) -> duckdb.DuckDBPyConnection:
        """获取写连接（独占模式）。"""
        if self._writer_conn is None:
            self._writer_conn = self._create_writer_connection()
        return self._writer_conn

    @property
    def db_path(self) -> Path:
        """获取数据库文件路径。"""
        if self._db_path is None:
            db_config = self.config.database
            if db_config.mode == "memory":
                raise RuntimeError("Memory mode does not have a database file path")
            self._db_path = self.kb_path / db_config.filename
        return self._db_path

    @property
    def is_file_mode(self) -> bool:
        """是否为文件模式。"""
        return self.config.database.mode == "file"

    def _create_writer_connection(self) -> duckdb.DuckDBPyConnection:
        """创建写连接。

        Returns:
            DuckDB 连接实例。
        """
        db_config = self.config.database

        if db_config.mode == "memory":
            conn = duckdb.connect()
            logger.debug("Database connection established (in-memory mode)")
            return conn

        # 文件模式
        self._db_path = self.kb_path / db_config.filename
        self._db_path.parent.mkdir(parents=True, exist_ok=True)

        conn = duckdb.connect(str(self._db_path))

        # 配置 WAL 模式
        if db_config.wal_mode:
            conn.execute("PRAGMA wal_mode='true'")

        # 配置并行查询
        conn.execute(f"PRAGMA threads={db_config.threads}")

        logger.debug(f"Writer connection established: {self._db_path}")
        return conn

    def create_reader_connection(self) -> duckdb.DuckDBPyConnection:
        """创建只读连接。

        Returns:
            只读 DuckDB 连接实例。
        """
        if not self.is_file_mode:
            # 内存模式返回同一连接
            return self.writer_conn

        conn = duckdb.connect(str(self.db_path), read_only=True)
        logger.debug("Reader connection established")
        return conn

    @contextmanager
    def reader(self) -> Generator[duckdb.DuckDBPyConnection, None, None]:
        """只读连接上下文管理器。

        用法：
            with engine.reader() as conn:
                result = conn.execute("SELECT ...").fetchall()

        Yields:
            只读数据库连接。
        """
        conn = self.create_reader_connection()
        try:
            yield conn
        finally:
            conn.close()

    def execute_write(
        self,
        sql: str,
        params: list | None = None,
    ) -> duckdb.DuckDBPyConnection:
        """执行写操作（线程安全）。

        Args:
            sql: SQL 语句。
            params: 参数列表。

        Returns:
            执行后的游标。
        """
        with self._write_lock:
            if params:
                return self.writer_conn.execute(sql, params)
            return self.writer_conn.execute(sql)

    def close(self) -> None:
        """关闭所有连接。"""
        if self._writer_conn is not None:
            self._writer_conn.close()
            self._writer_conn = None
            logger.debug("Writer connection closed")
```

#### 3.2.3 查询操作改造

```python
# src/duckkb/core/mixins/search.py
"""检索能力 Mixin（读写分离版）。"""

import asyncio
from typing import Any

from duckkb.core.base import BaseEngine
from duckkb.exceptions import DatabaseError
from duckkb.logger import logger


class SearchMixin(BaseEngine):
    """检索能力 Mixin（读写分离版）。

    所有读操作使用只读连接，支持并发读取。
    """

    async def search(
        self,
        query: str,
        *,
        node_type: str | None = None,
        limit: int = 10,
        alpha: float = 0.5,
    ) -> list[dict[str, Any]]:
        """智能混合搜索。"""
        if not query:
            return []

        query_vector = await self._get_query_vector(query)
        if not query_vector:
            logger.warning("Failed to generate query embedding")
            return []

        return await self._execute_hybrid_search(
            query=query,
            query_vector=query_vector,
            node_type=node_type,
            limit=limit,
            alpha=alpha,
        )

    async def _execute_hybrid_search(
        self,
        query: str,
        query_vector: list[float],
        node_type: str | None,
        limit: int,
        alpha: float,
    ) -> list[dict[str, Any]]:
        """执行混合检索（使用只读连接）。"""
        # ... SQL 构建逻辑保持不变 ...

        def _execute() -> list[Any]:
            with self.reader() as conn:  # 使用只读连接
                if fts_params:
                    return conn.execute(sql, fts_params).fetchall()
                return conn.execute(sql).fetchall()

        try:
            rows = await asyncio.to_thread(_execute)
            return self._process_results(rows)
        except Exception as e:
            logger.error(f"Hybrid search failed: {e}")
            raise DatabaseError(f"Hybrid search failed: {e}") from e

    async def vector_search(
        self,
        query: str,
        *,
        node_type: str | None = None,
        limit: int = 10,
    ) -> list[dict[str, Any]]:
        """纯向量检索（使用只读连接）。"""
        # ... 实现类似 _execute_hybrid_search ...

    async def fts_search(
        self,
        query: str,
        *,
        node_type: str | None = None,
        limit: int = 10,
    ) -> list[dict[str, Any]]:
        """纯全文检索（使用只读连接）。"""
        # ... 实现类似 _execute_hybrid_search ...

    async def get_source_record(
        self,
        source_table: str,
        source_id: int,
    ) -> dict[str, Any] | None:
        """回捞原始记录（使用只读连接）。"""
        validate_table_name(source_table)

        def _fetch() -> dict[str, Any] | None:
            with self.reader() as conn:
                row = conn.execute(
                    f"SELECT * FROM {source_table} WHERE __id = ?",
                    [source_id],
                ).fetchone()
                if not row:
                    return None

                cursor = conn.execute(f"SELECT * FROM {source_table} LIMIT 0")
                columns = [desc[0] for desc in cursor.description]
                return dict(zip(columns, row, strict=True))

        return await asyncio.to_thread(_fetch)

    async def query_raw_sql(self, sql: str) -> list[dict[str, Any]]:
        """安全执行原始 SQL 查询（使用只读连接）。"""
        sql_stripped = sql.strip()

        if not re.search(r"\bLIMIT\s+\d+", sql_stripped.upper()):
            sql = sql_stripped + f" LIMIT {QUERY_DEFAULT_LIMIT}"

        def _execute() -> list[dict[str, Any]]:
            with self.reader() as conn:
                cursor = conn.execute(sql)
                if not cursor.description:
                    return []
                columns = [desc[0] for desc in cursor.description]
                rows = cursor.fetchall()
                return [dict(zip(columns, row, strict=True)) for row in rows]

        return await asyncio.to_thread(_execute)
```

#### 3.2.4 导入操作改造

```python
# src/duckkb/core/mixins/import_.py
"""知识导入能力 Mixin（读写分离版）。"""

import asyncio
from typing import Any

from duckkb.core.base import BaseEngine
from duckkb.logger import logger


class ImportMixin(BaseEngine):
    """知识导入能力 Mixin（读写分离版）。

    导入操作使用写连接，通过 asyncio.Lock 串行化。
    """

    def __init__(self, *args, **kwargs) -> None:
        """初始化导入 Mixin。"""
        super().__init__(*args, **kwargs)
        self._import_lock = asyncio.Lock()  # 必须保留

    async def import_knowledge_bundle(self, temp_file_path: str) -> dict[str, Any]:
        """导入知识包（使用写连接）。"""
        async with self._import_lock:  # 串行化导入
            # ... 导入逻辑保持不变 ...

    async def _execute_import_in_transaction(
        self,
        nodes_data: list[dict[str, Any]],
        edges_data: list[dict[str, Any]],
    ) -> dict[str, Any]:
        """在单一事务中执行所有导入操作。"""

        def _execute() -> dict[str, Any]:
            with self._write_lock:  # 线程安全保护
                try:
                    self.writer_conn.begin()
                    # ... 导入逻辑 ...
                    self.writer_conn.commit()
                    return result
                except Exception as e:
                    self.writer_conn.rollback()
                    logger.error(f"Transaction rolled back: {e}")
                    raise

        return await asyncio.to_thread(_execute)
```

### 3.3 配置变更

```yaml
# config.yaml
embedding:
  model: text-embedding-3-small
  dim: 1536

log_level: INFO

global:
  chunk_size: 800
  embedding_model: text-embedding-3-small
  tokenizer: jieba

# 新增数据库配置
database:
  mode: file          # "memory" | "file"
  filename: kb.db     # 数据库文件名
  wal_mode: true      # 启用 WAL 模式
  threads: 4          # 并行查询线程数

ontology:
  # ... 本体定义保持不变 ...
```

## 四、数据迁移策略

### 4.1 从内存模式迁移到文件模式

由于内存模式的数据不持久化，迁移策略如下：

1. **首次启动**：文件模式下数据库为空，从 JSONL 文件加载历史数据
2. **后续启动**：直接从数据库文件加载，无需重新导入 JSONL

```python
# src/duckkb/core/engine.py

async def _load_existing_data(self) -> None:
    """从文件系统加载已有数据。"""
    db_config = self.config.database

    if db_config.mode == "file":
        # 文件模式：检查数据库是否已有数据
        db_path = self.kb_path / db_config.filename
        if db_path.exists():
            # 数据库已存在，检查是否有数据
            count = self.conn.execute(
                "SELECT COUNT(*) FROM information_schema.tables"
            ).fetchone()[0]
            if count > 0:
                logger.info(f"Database already exists: {db_path}")
                return

    # 内存模式或空数据库：从 JSONL 加载
    data_dir = self.config.storage.data_dir
    if not data_dir.exists():
        logger.debug(f"Data directory does not exist: {data_dir}")
        return

    # ... 加载逻辑 ...
```

### 4.2 数据持久化

文件模式下，数据自动持久化到 `kb.db` 文件，但仍保留 JSONL 导出作为备份：

```python
async def _dump_to_shadow_dir(
    self,
    upserted_ids: dict[str, list[int]],
    deleted_ids: dict[str, list[int]],
) -> dict[str, int]:
    """导出数据到影子目录（备份）。"""
    # 文件模式下，数据已在 kb.db 中持久化
    # JSONL 导出作为备份和迁移用途
    # ... 导出逻辑保持不变 ...
```

## 五、并发测试

### 5.1 并发查询测试

```python
# tests/test_concurrency.py
"""并发能力测试。"""

import asyncio
import pytest

from duckkb import Engine


class TestConcurrency:
    """并发能力测试。"""

    @pytest.fixture
    async def engine(self, tmp_path):
        """创建测试引擎。"""
        engine = Engine(tmp_path)
        engine.initialize()
        await engine.async_initialize()
        yield engine
        engine.close()

    @pytest.mark.asyncio
    async def test_concurrent_searches(self, engine: Engine) -> None:
        """测试多个查询并发执行。"""
        # 准备测试数据
        await engine.import_knowledge_bundle(...)

        # 并发执行 10 个查询
        queries = [f"查询 {i}" for i in range(10)]
        tasks = [engine.search(q, limit=5) for q in queries]
        results = await asyncio.gather(*tasks)

        # 验证所有查询都返回结果
        assert len(results) == 10
        for result in results:
            assert isinstance(result, list)

    @pytest.mark.asyncio
    async def test_import_and_search_concurrent(self, engine: Engine) -> None:
        """测试导入与查询并发执行。"""
        # 准备两个导入任务
        import_task1 = asyncio.create_task(
            engine.import_knowledge_bundle(...)
        )
        import_task2 = asyncio.create_task(
            engine.import_knowledge_bundle(...)
        )

        # 同时执行查询
        search_tasks = [
            asyncio.create_task(engine.search(f"查询 {i}"))
            for i in range(5)
        ]

        # 等待所有任务完成
        import_results = await asyncio.gather(import_task1, import_task2)
        search_results = await asyncio.gather(*search_tasks)

        # 验证导入结果
        assert all(r["status"] == "success" for r in import_results)

        # 验证查询结果
        assert len(search_results) == 5

    @pytest.mark.asyncio
    async def test_sequential_imports(self, engine: Engine) -> None:
        """测试导入串行化。"""
        # 两个导入任务应该串行执行
        import_task1 = asyncio.create_task(
            engine.import_knowledge_bundle(...)
        )
        import_task2 = asyncio.create_task(
            engine.import_knowledge_bundle(...)
        )

        results = await asyncio.gather(import_task1, import_task2)

        # 验证两个导入都成功
        assert all(r["status"] == "success" for r in results)
```

## 六、实施步骤

### 阶段 1: 验证 DuckDB 并发能力（必须先完成）

1. 创建 `tests/test_duckdb_concurrency.py`
2. 运行测试验证 DuckDB 文件模式的并发支持
3. 如果测试失败，需要调整方案

### 阶段 2: 实现读写分离

1. 修改 `src/duckkb/core/config/models.py`，添加 `DatabaseConfig`
2. 修改 `src/duckkb/core/mixins/db.py`，实现读写分离连接管理
3. 修改 `src/duckkb/core/mixins/search.py`，使用只读连接
4. 修改 `src/duckkb/core/mixins/import_.py`，使用写连接

### 阶段 3: 更新配置和测试

1. 更新 `config.yaml`，添加 `database` 配置节
2. 创建 `tests/test_concurrency.py`，验证并发能力
3. 运行所有测试，确保向后兼容

### 阶段 4: 文档和迁移指南

1. 更新 README.md，说明文件模式的配置
2. 提供从内存模式迁移到文件模式的指南

## 七、风险评估

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| DuckDB 并发测试失败 | 高 | 需要先验证，失败则采用方案 B（全局锁） |
| 文件模式性能下降 | 中 | 启用 WAL 模式，优化查询 |
| 数据迁移丢失 | 高 | 保留 JSONL 导出作为备份 |
| 向后兼容性 | 中 | 保留内存模式选项，默认使用文件模式 |

## 八、预期效果

实施完成后：

| 场景 | 当前状态 | 改进后 |
|------|----------|--------|
| 多个查询并发 | ❌ 不安全 | ✅ 安全并发 |
| 导入 + 查询并发 | ❌ 不安全 | ✅ 安全并发 |
| 多个导入并发 | ✅ 安全（有锁） | ✅ 安全（有锁） |
| 数据持久化 | ❌ 内存中 | ✅ 文件持久化 |
