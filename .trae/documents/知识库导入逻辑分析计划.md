# 知识库导入逻辑分析计划

## 一、分析范围

分析 `ImportMixin` 及相关模块的导入逻辑，识别潜在问题和改进点。

**核心文件**：
- [import_.py](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/import_.py) - 导入主逻辑
- [db.py](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/db.py) - 数据库连接管理
- [index.py](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/index.py) - 搜索索引管理
- [chunking.py](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/chunking.py) - 文本切片
- [embedding.py](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/embedding.py) - 向量嵌入
- [rwlock.py](file:///Users/yi/Code/duckkb/src/duckkb/utils/rwlock.py) - 公平读写锁

---

## 二、导入流程概览

```
import_knowledge_bundle()
    │
    ├─ 1. 读取 YAML + Schema 校验
    │
    ├─ 2. _execute_import_in_transaction() [单一事务]
    │      ├─ _import_nodes_sync() → upsert/delete 节点
    │      ├─ _import_edges_sync() → upsert/delete 边
    │      ├─ _validate_edge_references() → 边引用完整性检查
    │      └─ _build_index_for_ids_sync() → 构建索引
    │
    ├─ 3. _compute_vectors_async() [事务后异步]
    │
    ├─ 4. _dump_to_shadow_dir() → 影子导出
    │
    └─ 5. _atomic_replace_data_dir() → 原子替换
```

---

## 三、发现的问题

### 问题 1：文本切片逻辑重复且不一致（高优先级）

**位置**：
- [chunking.py:36-68](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/chunking.py#L36-L68) - `ChunkingMixin.chunk_text()` - 滑动窗口
- [import_.py:866-904](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/import_.py#L866-L904) - `ImportMixin._chunk_text_sync()` - 滑动窗口（fallback）
- [index.py:198-221](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/index.py#L198-L221) - `IndexMixin._chunk_text()` - **简单分块（无滑动窗口）**

**问题**：
1. 同一切片逻辑在三个地方有实现
2. `IndexMixin._chunk_text()` 的 fallback 实现使用简单分块（无重叠），而其他两处使用滑动窗口
3. 代码重复增加维护成本，实现不一致可能导致行为差异

**影响**：如果 `ChunkingMixin` 未被正确继承，`IndexMixin` 会使用不一致的切片策略。

---

### 问题 2：向量计算未利用批量 API（中优先级）

**位置**：[import_.py:1040-1078](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/import_.py#L1040-L1078)

```python
for record in records:
    for chunk_seq, chunk in enumerate(chunks):
        vector = await self.embed_single(chunk)  # 逐个调用
```

**问题**：
- `_compute_vectors_async()` 逐个调用 `embed_single()`
- `EmbeddingMixin.embed()` 支持批量计算，但未被利用
- 每次调用都是一次 HTTP 请求，效率低下

**影响**：大量数据导入时，向量计算时间会显著增加。

---

### 问题 3：边表不存在时静默跳过（中优先级）

**位置**：[import_.py:636-638](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/import_.py#L636-L638)

```python
if not self._table_exists_in_conn(conn, table_name):
    logger.warning(f"Edge table {table_name} does not exist, skipping upsert")
    return 0
```

**问题**：
- 边表不存在时只记录警告，不抛出异常
- 用户可能不知道边数据没有被导入
- 返回值 `0` 被当作成功计数，掩盖了问题

**影响**：数据丢失风险，用户难以察觉。

---

### 问题 4：向量计算失败时静默继续（中优先级）

**位置**：[import_.py:1075-1078](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/import_.py#L1075-L1078)

```python
except Exception as e:
    logger.error(f"Failed to compute vector for {table_name}.{field_name}: {e}")
    # 继续执行，不抛出异常
```

**问题**：
- 向量计算失败时只记录日志，不抛出异常
- 导入操作可能"部分成功"：节点已入库，但向量未计算
- 用户无法通过返回值判断向量计算是否成功

**影响**：搜索功能可能缺失部分数据的向量，影响检索质量。

---

### 问题 5：事务内执行耗时分词操作（低优先级）

**位置**：[import_.py:830-837](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/import_.py#L830-L837)

```python
for chunk_seq, chunk in enumerate(chunks):
    fts_content = self._get_or_compute_fts_sync(conn, chunk, content_hash)
```

**问题**：
- `_build_index_for_ids_sync()` 在事务内执行分词操作
- 分词可能比较耗时，会延长事务持有时间
- 向量计算已设计为延迟到事务后，但分词仍在事务内

**影响**：大量数据导入时，事务持有时间较长，可能影响并发性能。

---

### 问题 6：ID 碰撞风险（低优先级）

**位置**：[storage.py:13-27](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/storage.py#L13-L27)

```python
def compute_deterministic_id(identity_values: list) -> int:
    hash_hex = hashlib.sha256(combined.encode()).hexdigest()
    return int(hash_hex[:16], 16) % max_int64
```

**问题**：
- 使用 SHA256 前 16 位取模生成 INT64 ID
- 对于大规模数据集（>10亿条），碰撞概率会增加
- 碰撞会导致数据覆盖

**影响**：大规模数据集存在潜在的数据覆盖风险。

---

### 问题 7：影子目录清理时机（低优先级）

**位置**：[import_.py:139-145](file:///Users/yi/Code/duckkb/src/duckkb/core/mixins/import_.py#L139-L145)

**问题**：
- 异常时清理影子目录，但 backup 目录可能残留
- `_atomic_replace_data_dir()` 成功后清理 backup，但如果清理失败只记录警告

**影响**：磁盘空间可能被 backup 目录占用。

---

## 四、架构优点

1. **原子同步协议**：影子目录 + 原子替换，确保数据一致性
2. **公平读写锁**：避免写饥饿问题，支持多读并发
3. **缓存机制**：分词和向量结果缓存，避免重复计算
4. **事务包装**：所有数据库操作在单一事务中执行，保证原子性
5. **异步设计**：核心逻辑使用 async/await，阻塞 I/O 通过 `asyncio.to_thread` 封装
6. **Schema 校验**：导入前进行完整的 JSON Schema 校验，提供精确的错误位置

---

## 五、建议修复方案

### 修复 1：统一切片逻辑

**方案**：
1. 保留 `ChunkingMixin.chunk_text()` 作为唯一实现
2. 删除 `ImportMixin._chunk_text_sync()` 和 `IndexMixin._chunk_text()` 中的 fallback 实现
3. 如果 Mixin 未被正确继承，抛出明确的异常

---

### 修复 2：批量向量计算

**方案**：
1. 收集所有需要计算向量的 chunk
2. 批量调用 `embed()` 一次请求
3. 批量更新缓存和索引

---

### 修复 3：边表不存在时抛出异常

**方案**：
1. 将 `logger.warning` 改为抛出异常
2. 或返回错误信息，让用户知道导入失败的原因

---

### 修复 4：向量计算失败处理

**方案**：
1. 添加配置选项，允许用户选择：
   - `strict`：向量计算失败时回滚整个导入
   - `lenient`：向量计算失败时继续，但在返回值中标记失败数量

---

### 修复 5：分词移出事务（可选）

**方案**：
1. 将分词操作移到事务外，类似向量计算的处理方式
2. 在事务内只写入预计算好的分词结果

---

## 六、执行计划

| 序号 | 任务 | 优先级 | 预估影响 |
|------|------|--------|----------|
| 1 | 统一切片逻辑 | 高 | 修复潜在的数据不一致 |
| 2 | 批量向量计算 | 中 | 提升导入性能 |
| 3 | 边表不存在时抛出异常 | 中 | 避免数据丢失 |
| 4 | 向量计算失败处理 | 中 | 提升可观测性 |
| 5 | 分词移出事务 | 低 | 优化并发性能 |
| 6 | ID 碰撞风险文档化 | 低 | 提升用户认知 |
| 7 | backup 目录清理机制 | 低 | 磁盘空间管理 |

---

## 七、待确认事项

1. 是否需要修复所有问题，还是只修复高优先级问题？
2. 向量计算失败时的默认行为应该是 `strict` 还是 `lenient`？
3. 是否需要添加单元测试覆盖这些边界情况？
